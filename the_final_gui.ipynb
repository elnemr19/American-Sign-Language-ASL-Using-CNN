{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0c3d556-637e-497d-8263-4da76addb642",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.figure import Figure \n",
    "from matplotlib.backends.backend_tkagg import (FigureCanvasTkAgg, NavigationToolbar2Tk) \n",
    "import seaborn as sns\n",
    "import os\n",
    "#import openCV\n",
    "import cv2\n",
    "import random\n",
    "import glob as gb\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D, Input\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import tkinter as tk\n",
    "from tkinter import *\n",
    "from tkinter import messagebox\n",
    "from tkinter import filedialog\n",
    "from tkinter import font\n",
    "import PIL\n",
    "from PIL import  Image,ImageTk\n",
    "#from ImageTK import photoIma\n",
    "import customtkinter as ctk\n",
    "from tkinter import filedialog\n",
    "import tkinter.filedialog\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f38e62a0-ee2c-48ac-87f1-e6773282b8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Tk()\n",
    "screen_width = root.winfo_screenwidth()\n",
    "screen_height = root.winfo_screenheight()\n",
    "root.geometry(f\"{screen_width}x{screen_height}\")\n",
    "frame = Frame(root, width=screen_width, height=screen_height)\n",
    "frame.place(relheight=1, relwidth=1)\n",
    "#D:\\images\\photo_5868215891450249358_y.jpg\n",
    "img = ImageTk.PhotoImage(Image.open(\"D://ML_dataset//NN_project//gui.jpg\"))\n",
    "lbl=Label(frame, image=img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8210874b-fad0-45e3-aee3-9663d1bc1cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl.place(relheight=1,relwidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f89b9a48-b6ea-4f3b-806b-7471169379a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size=64\n",
    "result =None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bccee31-4006-4493-b16c-90bde34012f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "code = {'A':0 ,'B':1,'C':2,'D':3,'E':4,'F':5,'G':6,'H':7,'I':8,'J':9,'K':10,'L':11,'M':12,'N':13,'Nothing':14,'O':15,'P':16,'Q':17,'R':18,'S':19,'Space':20,'T':21,'U':22,'V':23,'W':24,'X':25,'Y':26,'Z':27}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3c4ae19-9bab-43bc-bebe-d3828de76a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cbb384a-020b-41bb-9af7-1802eb061fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_image():\n",
    "    \"\"\"Opens a file dialog, displays the image, and predicts the class.\"\"\"\n",
    "    filename = filedialog.askopenfilename(initialdir=\"D://ML_dataset//NN_project//Signs//ASL_Dataset//prediction\",\n",
    "                                      title=\"Select a File\",\n",
    "                                      filetypes=((\"JPG Images\", \"*.jpg\"),\n",
    "                                                 (\"all files\", \"*.*\")))\n",
    "    \n",
    "       \n",
    "            # Open image using Pillow\n",
    "    image = Image.open(filename)\n",
    "    img_tk = ImageTk.PhotoImage(image)\n",
    "    image_label.config(image=img_tk)\n",
    "    image_label.image = img_tk\n",
    "    image_path = filename # Replace with your image path\n",
    "    preprocessed_image = preprocess_image(image_path,img_size )\n",
    "    model = keras.models.load_model(\"sign.keras\")\n",
    "    prediction = model.predict(preprocessed_image)\n",
    "    predicted_class = np.argmax(prediction, axis=1)\n",
    "    global result\n",
    "    result=getcode(predicted_class)\n",
    "    print(f'Predicted class: {predicted_class}')\n",
    "    lbl_output.config(text=result)\n",
    "        #except Exception as e:\n",
    "          #print(f\"Error opening image: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7063aa03-9a26-4bc7-8444-0ff0676e30b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path, img_size):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    # Resize the image to the specified size\n",
    "    image = cv2.resize(image, (img_size, img_size))\n",
    "    # Convert image to array and scale pixel values to [0, 1] if required by your model\n",
    "    image_array = np.array(image) \n",
    "    # Expand dimensions to match the input shape (1, img_size, img_size, 3)\n",
    "    image_array = np.expand_dims(image_array, axis=0)\n",
    "    return image_array\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "675ba8ff-36b5-4ab9-bdcb-f54c8abda14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getcode(n) : \n",
    "    for x , y in code.items() : \n",
    "        if n == y : \n",
    "            return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7b520d3-55cb-41f0-99dc-dc2dc1ffa0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_output = tk.Label(frame, text=result, font=('helvatic', 20), bg='azure3')\n",
    "lbl_output.place(x=510, y=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "718ef5c9-fe29-44c5-980a-ba7669e6c59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload button\n",
    "upload_button = Button(root, text=\"Upload Image\", command=upload_image)\n",
    "upload_button.place(x=515, y=320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44d86354-13d4-4fac-b238-fec6e95dddc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_label = Label(frame)\n",
    "image_label.place(x=630,y=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b337e1eb-ff92-4a26-a790-3e374c2f6dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 234ms/step\n",
      "Predicted class: [0]\n"
     ]
    }
   ],
   "source": [
    "# Label to display image\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bfb982-3f3e-426e-85cd-e9e4aaced39a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c413aa37-331b-450a-af58-d9ba26efd775",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
